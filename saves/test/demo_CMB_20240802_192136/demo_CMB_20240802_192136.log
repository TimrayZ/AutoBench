
---------------custom config--------------
run: 
    mode: autoline
save: 
    en: True
    pub: 
        prefix: demo_CMB
        subdir: test
gpt: 
    model: 4om
autoline: 
    probset: 
        path: data/HDLBits/HDLBits_data.jsonl
        mutant_path: data/HDLBits/HDLBits_data_mutants.jsonl
        only: ['conditional']
    promptscript: pychecker
    timeout: 40
------------------------------------------
------config info (custom + default)------
run: 
    version: 5.0
    author: Ruidi Qiu - Technical University of Munich
    time: 20240802_192136
    custom_path: config/demos/CMB_template.yaml
    mode: autoline
    hostname: resi08
    pid: 3660137
save: 
    en: True
    root: saves/test/demo_CMB_20240802_192136/
    pub: 
        prefix: demo_CMB
        dir: saves/
        subdir: test/
    log: 
        en: True
        dir: logs/
        notes: None
        cfg_pmode: iwantall
    message: 
        en: True
        dir: messages/
        format: json
    iverilog: 
        en: True
        subdir: ivcode_nodebug
load: 
    prompt: 
        path: config/initial_prompts/prompt1.txt
        pick_idx: []
    stage_template: 
        path: config/templates/stage_template0301.txt
gpt: 
    model: gpt-4o-mini-2024-07-18
    key_path: config/key_API.json
    temperature: None
    json_mode: False
    chatgpt: 
        start_form: chat
        one_time_talk: False
iverilog: 
    dir: 
    task_id: 
autoline: 
    probset: 
        path: data/HDLBits/HDLBits_data.jsonl
        mutant_path: data/HDLBits/HDLBits_data_mutants.jsonl
        gptgenRTL_path: None
        more_info_paths: []
        only: ['conditional']
        exclude: []
        exclude_json: None
        filter: [{}]
    checklist: 
        max: 3
    debug: 
        max: 5
        reboot: 1
        py_rollback: 2
    onlyrun: None
    promptscript: pychecker
    error_interruption: False
    timeout: 40
------------------------------------------

--------------default config--------------
run: 
    version: 5.0
    author: Ruidi Qiu - Technical University of Munich
    time: None
    custom_path: None
    mode: chatgpt
save: 
    en: True
    root: None
    pub: 
        prefix: None
        dir: saves/
        subdir: 
    log: 
        en: True
        dir: logs/
        notes: None
        cfg_pmode: iwantall
    message: 
        en: True
        dir: messages/
        format: json
    iverilog: 
        en: True
        subdir: ivcode_nodebug
load: 
    prompt: 
        path: config/initial_prompts/prompt1.txt
        pick_idx: []
    stage_template: 
        path: config/templates/stage_template0301.txt
gpt: 
    model: 4
    key_path: config/key_API.json
    temperature: None
    json_mode: False
    chatgpt: 
        start_form: chat
        one_time_talk: False
iverilog: 
    dir: 
    task_id: 
autoline: 
    probset: 
        path: None
        mutant_path: None
        gptgenRTL_path: None
        more_info_paths: []
        only: []
        exclude: []
        exclude_json: None
        filter: [{}]
    checklist: 
        max: 3
    debug: 
        max: 5
        reboot: 1
        py_rollback: 2
    onlyrun: None
    promptscript: None
    error_interruption: False
    timeout: 60
------------------------------------------

#################### task 1/1 [conditional] ####################
stage_0 ends (6.05s used, time: 19:21:43 2024-08-02)
stage_1 ends (4.31s used, time: 19:21:47 2024-08-02)
stage_2 ends (7.72s used, time: 19:21:55 2024-08-02)
stage_4 ends (12.23s used, time: 19:22:07 2024-08-02)
