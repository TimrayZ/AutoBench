
---------------custom config--------------
run: 
    mode: autoline
save: 
    en: True
    pub: 
        prefix: demo_CMB
        subdir: test
gpt: 
    model: 4om
autoline: 
    probset: 
        path: data/HDLBits/HDLBits_data.jsonl
        mutant_path: data/HDLBits/HDLBits_data_mutants.jsonl
        only: ['conditional']
    promptscript: pychecker
    timeout: 40
------------------------------------------
------config info (custom + default)------
run: 
    version: 5.0
    author: Ruidi Qiu - Technical University of Munich
    time: 20240802_185832
    custom_path: config/demos/CMB_template.yaml
    mode: autoline
    hostname: resi08
    pid: 3656784
save: 
    en: True
    root: saves/test/demo_CMB_20240802_185832/
    pub: 
        prefix: demo_CMB
        dir: saves/
        subdir: test/
    log: 
        en: True
        dir: logs/
        notes: None
        cfg_pmode: iwantall
    message: 
        en: True
        dir: messages/
        format: json
    iverilog: 
        en: True
        subdir: ivcode_nodebug
load: 
    prompt: 
        path: config/initial_prompts/prompt1.txt
        pick_idx: []
    stage_template: 
        path: config/templates/stage_template0301.txt
gpt: 
    model: gpt-4o-mini-2024-07-18
    key_path: config/key_API.json
    temperature: None
    json_mode: False
    chatgpt: 
        start_form: chat
        one_time_talk: False
iverilog: 
    dir: 
    task_id: 
autoline: 
    probset: 
        path: data/HDLBits/HDLBits_data.jsonl
        mutant_path: data/HDLBits/HDLBits_data_mutants.jsonl
        gptgenRTL_path: None
        more_info_paths: []
        only: ['conditional']
        exclude: []
        exclude_json: None
        filter: [{}]
    checklist: 
        max: 3
    debug: 
        max: 5
        reboot: 1
        py_rollback: 2
    onlyrun: None
    promptscript: pychecker
    error_interruption: False
    timeout: 40
------------------------------------------

--------------default config--------------
run: 
    version: 5.0
    author: Ruidi Qiu - Technical University of Munich
    time: None
    custom_path: None
    mode: chatgpt
save: 
    en: True
    root: None
    pub: 
        prefix: None
        dir: saves/
        subdir: 
    log: 
        en: True
        dir: logs/
        notes: None
        cfg_pmode: iwantall
    message: 
        en: True
        dir: messages/
        format: json
    iverilog: 
        en: True
        subdir: ivcode_nodebug
load: 
    prompt: 
        path: config/initial_prompts/prompt1.txt
        pick_idx: []
    stage_template: 
        path: config/templates/stage_template0301.txt
gpt: 
    model: 4
    key_path: config/key_API.json
    temperature: None
    json_mode: False
    chatgpt: 
        start_form: chat
        one_time_talk: False
iverilog: 
    dir: 
    task_id: 
autoline: 
    probset: 
        path: None
        mutant_path: None
        gptgenRTL_path: None
        more_info_paths: []
        only: []
        exclude: []
        exclude_json: None
        filter: [{}]
    checklist: 
        max: 3
    debug: 
        max: 5
        reboot: 1
        py_rollback: 2
    onlyrun: None
    promptscript: None
    error_interruption: False
    timeout: 60
------------------------------------------

#################### task 1/1 [conditional] ####################
stage_0 ends (2.68s used, time: 18:58:35 2024-08-02)
stage_1 ends (2.80s used, time: 18:58:38 2024-08-02)
stage_2 ends (5.16s used, time: 18:58:43 2024-08-02)
stage_4 ends (11.05s used, time: 18:58:54 2024-08-02)
stage_checklist ends (0.67s used, time: 18:58:55 2024-08-02)
{{ERROR}} [conditional] 'WF_pychecker' object has no attribute 'stage5'

########## Analyze of Chatbench_RunInfo ##########

#### pass numbers:
Eval2 : 0
Eval1 : 0
Eval0 : 0
total : 1 (Failed: 1)

#### tokens and cost:
average prompt tokens: 0
average completion tokens: 0
total cost: 0.0000
average cost: 0.0000

#### time:
average time: 22.38s

#### debug info table:
debug info table:
         | un-debugged | debugged | total |
failed   |           1 |        0 |     1 |
Eval0    |           0 |        0 |     0 |
Eval1    |           0 |        0 |     0 |
Eval2    |           0 |        0 |     0 |

#### Eval2 ratio:

loose Eval2 pass metric applied: R = 0.80


